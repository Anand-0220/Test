{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Anaconda_vs_Miniconda\r\n",
      "'Approaching categorical vars.ipynb'\r\n",
      " bin\r\n",
      " catinthedatii\r\n",
      " C_Indrani_Aditya_Odyssey_Dharani.pdf\r\n",
      " C_Indrani_Harrys_Mansion_Dharani.pdf\r\n",
      "'Cross validation .ipynb'\r\n",
      " Desktop\r\n",
      " Documents\r\n",
      " Downloads\r\n",
      " environment.yml\r\n",
      " examples.desktop\r\n",
      " miniconda3\r\n",
      " mnist_dataset.ipynb\r\n",
      " mnist_train.csv\r\n",
      " Music\r\n",
      "'Overfitting example using winequality-red data.ipynb'\r\n",
      " Pictures\r\n",
      " project\r\n",
      " Public\r\n",
      " requirements.txt\r\n",
      " scikit_learn_data\r\n",
      " snap\r\n",
      " Templates\r\n",
      " Untitled.ipynb\r\n",
      " untitled.txt\r\n",
      " Videos\r\n",
      " winequality-red.csv\r\n",
      " winequality-red.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {\n",
    "    \"Freezing\": 0,\n",
    "    \"Warm\": 1,\n",
    "    \"Cold\": 2,\n",
    "    \"Boiling Hot\": 3,\n",
    "    \"Hot\": 4,\n",
    "    \"Lava Hot\": 5\n",
    "}\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"/home/anand/catinthedatii/cat_train.csv\")\n",
    "\n",
    "df.loc[:,\"ord_2\"] = df.ord_2.map(mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label Encoding i.e we are encoding every category as a numerical label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    142726\n",
       "1.0    124239\n",
       "2.0     97822\n",
       "3.0     84790\n",
       "4.0     67508\n",
       "5.0     64840\n",
       "Name: ord_2, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.ord_2.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# read the data\n",
    "df = pd.read_csv(\"/home/anand/catinthedatii/cat_train.csv\")\n",
    "\n",
    "# fill NaN values in ird_2 column\n",
    "df.loc[:,\"ord_2\"] = df.ord_2.fillna(\"NONE\")\n",
    "\n",
    "# initialize LabelEncoder\n",
    "lbl_enc = preprocessing.LabelEncoder()\n",
    "\n",
    "# fit label encoder and transform values on ord_2 column\n",
    "# P.S - do not use this directly. fit first, then transform.\n",
    "df.loc[:,\"ord_2\"] = lbl_enc.fit_transform(df.ord_2.values)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We can use this directly in many tree-based models:\n",
    "\n",
    "Decision Trees,\n",
    "Random Forests,\n",
    "Extra Trees,\n",
    "Or any kind of boosted trees moodel -\n",
    "    XGBoost,\n",
    "    GBM,\n",
    "    LightGBM.\n",
    "\n",
    "\n",
    "This type of encoding cannot be used in linear models, support vector machines or neural networks as they expect data to be normalized (or standardized).\n",
    "For these type of models, we can binarize the data.\n",
    "\n",
    "Freezing --> 0 --> 0 0 0\n",
    "Warm     --> 1 --> 0 0 1\n",
    "Cold     --> 2 --> 0 1 0\n",
    "Boiling Hot >3 --> 0 1 1\n",
    "Hot      --> 4 --> 1 0 0\n",
    "Lava Hot --> 5 --> 1 0 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72\n"
     ]
    }
   ],
   "source": [
    "# Introducing sparse format for binary variables\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# create our example of feature matrix\n",
    "example = np.array(\n",
    "    [\n",
    "        [0,0,1],\n",
    "        [1,0,0],\n",
    "        [1,0,1]\n",
    "    ]\n",
    ")\n",
    "\n",
    "#PRINT SIZE IN BYTES\n",
    "print(example.nbytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import sparse\n",
    "\n",
    "# One way to represent this matrix only with 1s would be some kind of dictionary method in which \n",
    "#keys are indices of rows and columns and value is 1\n",
    "\n",
    "# convert numpy array to sparse csr matrix\n",
    "sparse_example = sparse.csr_matrix(example)\n",
    "\n",
    "#print size of this sparse matrix\n",
    "print(sparse_example.data.nbytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 2)\t1\n",
      "  (1, 0)\t1\n",
      "  (2, 0)\t1\n",
      "  (2, 2)\t1\n"
     ]
    }
   ],
   "source": [
    "print(sparse_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n"
     ]
    }
   ],
   "source": [
    "print(sparse_example.data.nbytes +\n",
    "     sparse_example.indptr.nbytes +\n",
    "     sparse_example.indices.nbytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of dense array: 800000000\n",
      "Size of sparse array: 39974344\n",
      "Full size of the sparse array: 59965520\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import sparse\n",
    "\n",
    "n_rows = 1000\n",
    "n_cols = 100000\n",
    "\n",
    "# create a random binary matrix with only 5% values as 1s\n",
    "example = np.random.binomial(1,p=0.05,size=(n_rows,n_cols))\n",
    "\n",
    "# print size in bytes\n",
    "print(f\"Size of dense array: {example.nbytes}\")\n",
    "\n",
    "# convert numpy array to sparse CSR matrix\n",
    "sparse_example = sparse.csr_matrix(example)\n",
    "\n",
    "# print size of this in sparse matrix\n",
    "print(f\"Size of sparse array: {sparse_example.data.nbytes}\")\n",
    "\n",
    "full_size = (\n",
    "    sparse_example.data.nbytes +\n",
    "    sparse_example.indptr.nbytes +\n",
    "    sparse_example.indices.nbytes\n",
    ")\n",
    "\n",
    "print(f\"Full size of the sparse array: {full_size}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check other ways of representing a sparse matrix. Above mentioned is one way and a popular way"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One hot encoding\n",
    "\n",
    "Vector having only 1s and 0s and of the size = no. of categories in the variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# create random 1-d array with 1001 different categories (int)\n",
    "exanple = np.random.randint(1000,size=1000000)\n",
    "\n",
    "# Initialize one hot encoder from scikit-learn\n",
    "# keep sparse = False to get dense array\n",
    "ohe = preprocessing.OneHotEncoder(sparse=False)\n",
    "\n",
    "# fit and transform data with dense one hot encoder\n",
    "ohe_example = ohe.fit_transform(example.reshape(-1,1))\n",
    "\n",
    "# print size in bytes for dense array\n",
    "print(f\"Size of dense array: {ohe_example.data.nbytes}\")\n",
    "\n",
    "# Initialise OneHotEncoder from scikit-learn\n",
    "# keep sparse = True to get sparse array\n",
    "ohe = preprocessing.OneHotEncoder(sparse=True)\n",
    "\n",
    "# fit and transform data with sparse one hot encoder\n",
    "ohe_example = ohe.fit_transform(example.reshape(-1,1))\n",
    "\n",
    "# print size of this sparse matrix\n",
    "print(f\"Size of sparse array: {ohe_example.data.nbytes}\")\n",
    "\n",
    "full_size = (\n",
    "    ohe_example.data.nbytes +\n",
    "    ohe_example.indptr.nbytes +\n",
    "    ohe_example.indices.nbytes\n",
    ")\n",
    "\n",
    "# print full size of this sparse matrix\n",
    "print(f\"Full size of sparse array: {full_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
