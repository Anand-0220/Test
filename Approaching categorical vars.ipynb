{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Anaconda_vs_Miniconda\r\n",
      "'Approaching categorical vars.ipynb'\r\n",
      " bin\r\n",
      " catinthedatii\r\n",
      " C_Indrani_Aditya_Odyssey_Dharani.pdf\r\n",
      " C_Indrani_Harrys_Mansion_Dharani.pdf\r\n",
      "'Cross validation .ipynb'\r\n",
      " Desktop\r\n",
      " Documents\r\n",
      " Downloads\r\n",
      " environment.yml\r\n",
      " examples.desktop\r\n",
      " miniconda3\r\n",
      " mnist_dataset.ipynb\r\n",
      " mnist_train.csv\r\n",
      " Music\r\n",
      "'Overfitting example using winequality-red data.ipynb'\r\n",
      " Pictures\r\n",
      " project\r\n",
      " Public\r\n",
      " requirements.txt\r\n",
      " scikit_learn_data\r\n",
      " snap\r\n",
      " Templates\r\n",
      " Untitled.ipynb\r\n",
      " untitled.txt\r\n",
      " Videos\r\n",
      " winequality-red.csv\r\n",
      " winequality-red.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {\n",
    "    \"Freezing\": 0,\n",
    "    \"Warm\": 1,\n",
    "    \"Cold\": 2,\n",
    "    \"Boiling Hot\": 3,\n",
    "    \"Hot\": 4,\n",
    "    \"Lava Hot\": 5\n",
    "}\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"/home/anand/catinthedatii/cat_train.csv\")\n",
    "\n",
    "df.loc[:,\"ord_2\"] = df.ord_2.map(mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label Encoding i.e we are encoding every category as a numerical label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    142726\n",
       "1.0    124239\n",
       "2.0     97822\n",
       "3.0     84790\n",
       "4.0     67508\n",
       "5.0     64840\n",
       "Name: ord_2, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.ord_2.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# read the data\n",
    "df = pd.read_csv(\"/home/anand/catinthedatii/cat_train.csv\")\n",
    "\n",
    "# fill NaN values in ird_2 column\n",
    "df.loc[:,\"ord_2\"] = df.ord_2.fillna(\"NONE\")\n",
    "\n",
    "# initialize LabelEncoder\n",
    "lbl_enc = preprocessing.LabelEncoder()\n",
    "\n",
    "# fit label encoder and transform values on ord_2 column\n",
    "# P.S - do not use this directly. fit first, then transform.\n",
    "df.loc[:,\"ord_2\"] = lbl_enc.fit_transform(df.ord_2.values)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We can use this directly in many tree-based models:\n",
    "\n",
    "Decision Trees,\n",
    "Random Forests,\n",
    "Extra Trees,\n",
    "Or any kind of boosted trees moodel -\n",
    "    XGBoost,\n",
    "    GBM,\n",
    "    LightGBM.\n",
    "\n",
    "\n",
    "This type of encoding cannot be used in linear models, support vector machines or neural networks as they expect data to be normalized (or standardized).\n",
    "For these type of models, we can binarize the data.\n",
    "\n",
    "Freezing --> 0 --> 0 0 0\n",
    "Warm     --> 1 --> 0 0 1\n",
    "Cold     --> 2 --> 0 1 0\n",
    "Boiling Hot >3 --> 0 1 1\n",
    "Hot      --> 4 --> 1 0 0\n",
    "Lava Hot --> 5 --> 1 0 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72\n"
     ]
    }
   ],
   "source": [
    "# Introducing sparse format for binary variables\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# create our example of feature matrix\n",
    "example = np.array(\n",
    "    [\n",
    "        [0,0,1],\n",
    "        [1,0,0],\n",
    "        [1,0,1]\n",
    "    ]\n",
    ")\n",
    "\n",
    "#PRINT SIZE IN BYTES\n",
    "print(example.nbytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import sparse\n",
    "\n",
    "# One way to represent this matrix only with 1s would be some kind of dictionary method in which \n",
    "#keys are indices of rows and columns and value is 1\n",
    "\n",
    "# convert numpy array to sparse csr matrix\n",
    "sparse_example = sparse.csr_matrix(example)\n",
    "\n",
    "#print size of this sparse matrix\n",
    "print(sparse_example.data.nbytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 2)\t1\n",
      "  (1, 0)\t1\n",
      "  (2, 0)\t1\n",
      "  (2, 2)\t1\n"
     ]
    }
   ],
   "source": [
    "print(sparse_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n"
     ]
    }
   ],
   "source": [
    "print(sparse_example.data.nbytes +\n",
    "     sparse_example.indptr.nbytes +\n",
    "     sparse_example.indices.nbytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of dense array: 800000000\n",
      "Size of sparse array: 39974344\n",
      "Full size of the sparse array: 59965520\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import sparse\n",
    "\n",
    "n_rows = 1000\n",
    "n_cols = 100000\n",
    "\n",
    "# create a random binary matrix with only 5% values as 1s\n",
    "example = np.random.binomial(1,p=0.05,size=(n_rows,n_cols))\n",
    "\n",
    "# print size in bytes\n",
    "print(f\"Size of dense array: {example.nbytes}\")\n",
    "\n",
    "# convert numpy array to sparse CSR matrix\n",
    "sparse_example = sparse.csr_matrix(example)\n",
    "\n",
    "# print size of this in sparse matrix\n",
    "print(f\"Size of sparse array: {sparse_example.data.nbytes}\")\n",
    "\n",
    "full_size = (\n",
    "    sparse_example.data.nbytes +\n",
    "    sparse_example.indptr.nbytes +\n",
    "    sparse_example.indices.nbytes\n",
    ")\n",
    "\n",
    "print(f\"Full size of the sparse array: {full_size}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check other ways of representing a sparse matrix. Above mentioned is one way and a popular way"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One hot encoding\n",
    "\n",
    "Vector having only 1s and 0s and of the size = no. of categories in the variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# create random 1-d array with 1001 different categories (int)\n",
    "exanple = np.random.randint(1000,size=1000000)\n",
    "\n",
    "# Initialize one hot encoder from scikit-learn\n",
    "# keep sparse = False to get dense array\n",
    "ohe = preprocessing.OneHotEncoder(sparse=False)\n",
    "\n",
    "# fit and transform data with dense one hot encoder\n",
    "ohe_example = ohe.fit_transform(example.reshape(-1,1))\n",
    "\n",
    "# print size in bytes for dense array\n",
    "print(f\"Size of dense array: {ohe_example.data.nbytes}\")\n",
    "\n",
    "# Initialise OneHotEncoder from scikit-learn\n",
    "# keep sparse = True to get sparse array\n",
    "ohe = preprocessing.OneHotEncoder(sparse=True)\n",
    "\n",
    "# fit and transform data with sparse one hot encoder\n",
    "ohe_example = ohe.fit_transform(example.reshape(-1,1))\n",
    "\n",
    "# print size of this sparse matrix\n",
    "print(f\"Size of sparse array: {ohe_example.data.nbytes}\")\n",
    "\n",
    "full_size = (\n",
    "    ohe_example.data.nbytes +\n",
    "    ohe_example.indptr.nbytes +\n",
    "    ohe_example.indices.nbytes\n",
    ")\n",
    "\n",
    "# print full size of this sparse matrix\n",
    "print(f\"Full size of sparse array: {full_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling missing values and rare values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# read training data\n",
    "train = pd.read_csv(\"/home/anand/catinthedatii/cat_train.csv\")\n",
    "\n",
    "# read test data\n",
    "test = pd.read_csv(\"/home/anand/catinthedatii/cat_test.csv\")\n",
    "\n",
    "# create a fake target column for the test data so that we can distinguish test/train later\n",
    "test.loc[:,\"target\"] = -1\n",
    "\n",
    "# concatenate test and train data\n",
    "data = pd.concat([train,test]).reset_index(drop=True)\n",
    "\n",
    "# make a list of features we are interested in\n",
    "# id and target is something we should not encode\n",
    "\n",
    "features = [x for x in train.columns if x not in [\"id\",\"target\"]]\n",
    "\n",
    "# loop over the features list\n",
    "for feat in features:\n",
    "    # create a new instance of Labelencoder for each feature\n",
    "    lbl_enc = preprocessing.LabelEncoder()\n",
    "    \n",
    "    # note this trick here\n",
    "    # since its categorical data, we fillna with a string\n",
    "    # and we convert all data to string type so no matter its int or float, its converted to string\n",
    "    temp_col = data[feat].fillna(\"NONE\").astype(str).values\n",
    "    \n",
    "    # we can use fit_transform here as we do not have any extra test data that we need to transform seperately\n",
    "    data.loc[:,feat] = lbl_enc.fit_transform(temp_col)\n",
    "    \n",
    "\n",
    "# split the train and test dataset again\n",
    "train = data[data.target != -1].reset_index(drop=True)\n",
    "test = data[data.target == -1].reset_index(drop=True)\n",
    "\n",
    "# this trick wont work in a live setting if a new category comes up as in example of Real time bidding (RTB)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assume that the test data will have the same categories as training or you can intriduce a rare or unknown category to training to take care of new categories in test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "N    39978\n",
       "P    37890\n",
       "Y    36657\n",
       "A    36633\n",
       "R    33045\n",
       "U    32897\n",
       "M    32504\n",
       "X    32347\n",
       "C    32112\n",
       "H    31189\n",
       "Q    30145\n",
       "T    29723\n",
       "O    25610\n",
       "B    25212\n",
       "E    21871\n",
       "K    21676\n",
       "I    19805\n",
       "D    17284\n",
       "F    16721\n",
       "W     8268\n",
       "Z     5790\n",
       "S     4595\n",
       "G     3404\n",
       "V     3107\n",
       "J     1950\n",
       "L     1657\n",
       "Name: ord_4, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.ord_4.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "N       39978\n",
       "P       37890\n",
       "Y       36657\n",
       "A       36633\n",
       "R       33045\n",
       "U       32897\n",
       "M       32504\n",
       "X       32347\n",
       "C       32112\n",
       "H       31189\n",
       "Q       30145\n",
       "T       29723\n",
       "O       25610\n",
       "B       25212\n",
       "E       21871\n",
       "K       21676\n",
       "I       19805\n",
       "NONE    17930\n",
       "D       17284\n",
       "F       16721\n",
       "W        8268\n",
       "Z        5790\n",
       "S        4595\n",
       "G        3404\n",
       "V        3107\n",
       "J        1950\n",
       "L        1657\n",
       "Name: ord_4, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.ord_4 = df.ord_4.fillna(\"NONE\")\n",
    "df.ord_4.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "N       39978\n",
       "P       37890\n",
       "Y       36657\n",
       "A       36633\n",
       "R       33045\n",
       "U       32897\n",
       "M       32504\n",
       "X       32347\n",
       "C       32112\n",
       "H       31189\n",
       "Q       30145\n",
       "T       29723\n",
       "O       25610\n",
       "B       25212\n",
       "E       21871\n",
       "K       21676\n",
       "I       19805\n",
       "NONE    17930\n",
       "D       17284\n",
       "F       16721\n",
       "W        8268\n",
       "Z        5790\n",
       "S        4595\n",
       "RARE     3607\n",
       "G        3404\n",
       "V        3107\n",
       "Name: ord_4, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df.ord_4.value_counts()[df[\"ord_4\"]].values < 2000,\n",
    "      \"ord_4\"\n",
    "      ] = \"RARE\"\n",
    "\n",
    "df.ord_4.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, ..., False, False, False])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.ord_4.value_counts()[df[\"ord_4\"]].values < 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    487677\n",
       "1    112323\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.target.value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
