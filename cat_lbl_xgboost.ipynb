{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat_kfolds.ipynb       cat_test.csv\t    OHE_LogisticReg.ipynb\r\n",
      "cat_lbl_rf.ipynb       cat_train.csv\r\n",
      "cat_lbl_xgboost.ipynb  cat_train_folds.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 0, AUC = 0.7618007857634607\n",
      "Fold: 1, AUC = 0.759835244131747\n",
      "Fold: 2, AUC = 0.7629281380966259\n",
      "Fold: 3, AUC = 0.7625019696960602\n",
      "Fold: 4, AUC = 0.7622568603568567\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "\n",
    "def run(fold):\n",
    "    \n",
    "    df = pd.read_csv(\"/home/anand/catinthedatii/cat_train_folds.csv\")\n",
    "    \n",
    "    features =[\n",
    "        f for f in df.columns if f not in (\"id\",\"kfold\",\"target\")\n",
    "    ]\n",
    "    \n",
    "    # fill NaN values with NONE. Not that all columns are being converted to string as they are categories.\n",
    "    for col in features:\n",
    "        df.loc[:,col] = df[col].astype(str).fillna(\"NONE\")\n",
    "        \n",
    "    # now its time to label encode the features\n",
    "    for col in features:\n",
    "        \n",
    "        # initialize Labelencoder for each feature column\n",
    "        lbl = preprocessing.LabelEncoder()\n",
    "        \n",
    "        # fit label encoder on all the data. Note that we are fitting on all data and not just Train\n",
    "        lbl.fit(df[col])\n",
    "        \n",
    "        # transform all the data\n",
    "        df.loc[:,col] = lbl.transform(df[col])\n",
    "        \n",
    "    # get training data using folds\n",
    "    df_train = df[df.kfold != fold].reset_index(drop=True)\n",
    "    \n",
    "    # get validation data using folds\n",
    "    df_valid = df[df.kfold == fold].reset_index(drop=True)\n",
    "    \n",
    "    \n",
    "    # get training data\n",
    "    x_train = df_train[features].values\n",
    "    \n",
    "    # transform validation data\n",
    "    x_valid = df_valid[features].values\n",
    "    \n",
    "    # initialize XGBoost model. Deafults are max_depth = 3 and n_estimators = 100\n",
    "    model = xgb.XGBClassifier(n_jobs=-1,max_depth=7,n_estimators=200)\n",
    "    \n",
    "    # fit model on training data (ohe)\n",
    "    model.fit(x_train,df_train.target.values)\n",
    "    \n",
    "    #predict on validation data\n",
    "    # we need the probability values as we are calcuating AUC\n",
    "    # we will use the probability of 1s\n",
    "    valid_preds = model.predict_proba(x_valid)[:,1]\n",
    "    \n",
    "    # get roc auc score\n",
    "    auc = metrics.roc_auc_score(df_valid.target.values,valid_preds)\n",
    "    \n",
    "    # print auc\n",
    "    print(f\"Fold: {fold}, AUC = {auc}\")\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "       for fold_ in range(5):\n",
    "            run(fold_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
